#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨å­¦ä¹ æœºå™¨äºº
è‡ªåŠ¨æˆªå±ã€OCRè¯†åˆ«ã€åˆ¤æ–­å¹¶ç‚¹å‡»æœªå®Œæˆè¯¾ç¨‹
"""

import pyautogui
import time
import cv2
import numpy as np
from PIL import Image, ImageGrab
import re
import os
from datetime import datetime

# å°è¯•å¯¼å…¥OCRåº“
try:
    import pytesseract
    HAS_OCR = True
except ImportError:
    HAS_OCR = False
    print("âš ï¸  è­¦å‘Š: pytesseractæœªå®‰è£…ï¼Œå°†ä½¿ç”¨å¤‡ç”¨è¯†åˆ«æ–¹æ³•")
    print("   å®‰è£…: pip install pytesseract")


class AutoLearningBot:
    def __init__(self, base_image='lists.png'):
        """åˆå§‹åŒ–è‡ªåŠ¨å­¦ä¹ æœºå™¨äºº"""
        self.base_image = base_image
        self.window_offset_x = 0
        self.window_offset_y = 0
        
        # ä¸€çº§èœå•åæ ‡ï¼ˆçº¢è‰²æŒ‰é’®ï¼‰
        self.level1_menus = [
            {'id': 1, 'x': 665, 'y': 271},
            {'id': 2, 'x': 665, 'y': 461},
            {'id': 3, 'x': 665, 'y': 651},
            {'id': 4, 'x': 665, 'y': 841},
        ]
        
        # äºŒçº§èœå•åŒºåŸŸï¼ˆç›¸å¯¹äºä¸€çº§èœå•çš„åç§»ï¼‰
        self.level2_regions = {
            1: {'x': 50, 'y': 305, 'width': 500, 'height': 123},
            2: {'x': 50, 'y': 494, 'width': 500, 'height': 123},
            3: {'x': 50, 'y': 685, 'width': 500, 'height': 123},
            4: {'x': 50, 'y': 875, 'width': 500, 'height': 95},
        }
        
        self.log_file = f"learning_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
    def log(self, message):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_msg = f"[{timestamp}] {message}"
        print(log_msg)
        
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_msg + '\n')
    
    def find_window(self):
        """åœ¨å±å¹•ä¸ŠæŸ¥æ‰¾è¯¾ç¨‹åˆ—è¡¨çª—å£"""
        self.log("æ­£åœ¨æŸ¥æ‰¾è¯¾ç¨‹åˆ—è¡¨çª—å£...")
        
        try:
            # å°è¯•åœ¨å±å¹•ä¸Šå®šä½åŸºå‡†å›¾ç‰‡
            location = pyautogui.locateOnScreen(self.base_image, confidence=0.6)
            
            if location:
                self.window_offset_x = location.left
                self.window_offset_y = location.top
                self.log(f"âœ… æ‰¾åˆ°çª—å£ä½ç½®: ({self.window_offset_x}, {self.window_offset_y})")
                return True
            else:
                self.log("âŒ æœªæ‰¾åˆ°çª—å£ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•...")
                # å¤‡ç”¨ï¼šè®©ç”¨æˆ·æ‰‹åŠ¨ç‚¹å‡»
                self.log("è¯·å°†é¼ æ ‡ç§»åŠ¨åˆ°è¯¾ç¨‹åˆ—è¡¨å·¦ä¸Šè§’ï¼Œ5ç§’åè‡ªåŠ¨è®°å½•ä½ç½®...")
                time.sleep(5)
                pos = pyautogui.position()
                self.window_offset_x = pos[0]
                self.window_offset_y = pos[1]
                self.log(f"âœ… æ‰‹åŠ¨è®¾ç½®çª—å£ä½ç½®: ({self.window_offset_x}, {self.window_offset_y})")
                return True
                
        except Exception as e:
            self.log(f"âŒ æŸ¥æ‰¾çª—å£å¤±è´¥: {e}")
            return False
    
    def click_point(self, x, y, duration=0.3, delay=0.5):
        """ç‚¹å‡»æŒ‡å®šä½ç½®"""
        abs_x = self.window_offset_x + x
        abs_y = self.window_offset_y + y
        
        self.log(f"   ç‚¹å‡»: ({abs_x}, {abs_y})")
        pyautogui.moveTo(abs_x, abs_y, duration=duration)
        pyautogui.click()
        time.sleep(delay)
    
    def capture_region(self, x, y, width, height, save_path=None):
        """æˆªå–æŒ‡å®šåŒºåŸŸ"""
        abs_x = self.window_offset_x + x
        abs_y = self.window_offset_y + y
        
        # æˆªå›¾
        bbox = (abs_x, abs_y, abs_x + width, abs_y + height)
        screenshot = ImageGrab.grab(bbox=bbox)
        
        if save_path:
            screenshot.save(save_path)
            self.log(f"   æˆªå›¾ä¿å­˜: {save_path}")
        
        return screenshot
    
    def ocr_extract_hours(self, image):
        """ä½¿ç”¨OCRæå–å­¦æ—¶ä¿¡æ¯"""
        if not HAS_OCR:
            return []
        
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾æé«˜è¯†åˆ«ç‡
            img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
            
            # äºŒå€¼åŒ–
            _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)
            
            # OCRè¯†åˆ«
            # é…ç½®ï¼šåªè¯†åˆ«æ•°å­—ã€å°æ•°ç‚¹ã€æ–œæ å’Œä¸­æ–‡
            custom_config = r'--oem 3 --psm 6'
            text = pytesseract.image_to_string(binary, lang='chi_sim+eng', config=custom_config)
            
            self.log(f"   OCRè¯†åˆ«æ–‡æœ¬: {text[:100]}...")
            
            # æå–å­¦æ—¶ä¿¡æ¯ï¼šx.x/x.xå­¦æ—¶ æˆ– x/xå­¦æ—¶
            pattern = r'(\d+\.?\d*)\s*/\s*(\d+\.?\d*)\s*å­¦æ—¶'
            matches = re.findall(pattern, text)
            
            results = []
            for completed, total in matches:
                try:
                    c = float(completed)
                    t = float(total)
                    results.append({
                        'completed': c,
                        'total': t,
                        'is_incomplete': c < t,
                        'text': f"{c}/{t}å­¦æ—¶"
                    })
                except ValueError:
                    continue
            
            return results
            
        except Exception as e:
            self.log(f"   OCRé”™è¯¯: {e}")
            return []
    
    def detect_text_regions_opencv(self, image):
        """ä½¿ç”¨OpenCVæ£€æµ‹æ–‡æœ¬åŒºåŸŸï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
        
        # è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 50, 150)
        
        # è†¨èƒ€è¿æ¥æ–‡æœ¬
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 5))
        dilated = cv2.dilate(edges, kernel, iterations=1)
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        text_regions = []
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            # å­¦æ—¶æ–‡æœ¬ç‰¹å¾ï¼šå®½åº¦è¾ƒå¤§ï¼Œé«˜åº¦é€‚ä¸­
            if 80 < w < 300 and 15 < h < 40:
                text_regions.append({
                    'x': x,
                    'y': y,
                    'width': w,
                    'height': h,
                    'center_x': x + w // 2,
                    'center_y': y + h // 2
                })
        
        return text_regions
    
    def find_incomplete_courses(self, menu_id):
        """æŸ¥æ‰¾æœªå®Œæˆçš„è¯¾ç¨‹"""
        self.log(f"\n>>> åˆ†æèœå• {menu_id} çš„è¯¾ç¨‹...")
        
        # è·å–äºŒçº§èœå•åŒºåŸŸ
        region = self.level2_regions[menu_id]
        
        # æˆªå›¾
        timestamp = datetime.now().strftime('%H%M%S')
        screenshot_path = f"screenshot_menu{menu_id}_{timestamp}.png"
        screenshot = self.capture_region(
            region['x'], region['y'], 
            region['width'], region['height'],
            save_path=screenshot_path
        )
        
        # OCRè¯†åˆ«å­¦æ—¶
        hours_info = self.ocr_extract_hours(screenshot)
        
        if hours_info:
            self.log(f"   æ‰¾åˆ° {len(hours_info)} ä¸ªè¯¾ç¨‹:")
            incomplete_courses = []
            
            for i, info in enumerate(hours_info):
                status = "âŒ æœªå®Œæˆ" if info['is_incomplete'] else "âœ… å·²å®Œæˆ"
                self.log(f"   è¯¾ç¨‹ {i+1}: {info['text']} - {status}")
                
                if info['is_incomplete']:
                    incomplete_courses.append(info)
            
            return incomplete_courses, hours_info
        else:
            self.log("   âš ï¸  æœªè¯†åˆ«åˆ°å­¦æ—¶ä¿¡æ¯")
            
            # å¤‡ç”¨ï¼šæ£€æµ‹æ–‡æœ¬åŒºåŸŸ
            text_regions = self.detect_text_regions_opencv(screenshot)
            self.log(f"   æ£€æµ‹åˆ° {len(text_regions)} ä¸ªå¯èƒ½çš„æ–‡æœ¬åŒºåŸŸ")
            
            return [], []
    
    def click_incomplete_course(self, menu_id, course_index, hours_info):
        """ç‚¹å‡»æœªå®Œæˆçš„è¯¾ç¨‹"""
        region = self.level2_regions[menu_id]
        
        # ä¼°è®¡è¯¾ç¨‹çš„Yä½ç½®ï¼ˆå‡è®¾æ¯ä¸ªè¯¾ç¨‹çº¦40-50pxé«˜ï¼‰
        # ç¬¬ä¸€ä¸ªè¯¾ç¨‹åœ¨åŒºåŸŸé¡¶éƒ¨ï¼Œåç»­è¯¾ç¨‹ä¾æ¬¡å‘ä¸‹
        item_height = 45
        start_y = region['y'] + 30
        
        click_x = region['x'] + 150  # å­¦æ—¶æ–‡æœ¬å¤§æ¦‚åœ¨å·¦ä¾§150pxå¤„
        click_y = start_y + course_index * item_height
        
        self.log(f"   ç‚¹å‡»è¯¾ç¨‹ {course_index + 1}")
        self.click_point(click_x, click_y, duration=0.5, delay=1.0)
        
        return True
    
    def process_level1_menu(self, menu_id):
        """å¤„ç†ä¸€ä¸ªä¸€çº§èœå•"""
        self.log(f"\n{'='*60}")
        self.log(f"å¤„ç†ä¸€çº§èœå• {menu_id}")
        self.log(f"{'='*60}")
        
        # ç‚¹å‡»ä¸€çº§èœå•æŒ‰é’®
        menu = self.level1_menus[menu_id - 1]
        self.log("æ­¥éª¤1: ç‚¹å‡»ä¸€çº§èœå•å±•å¼€")
        self.click_point(menu['x'], menu['y'], delay=1.5)
        
        # ç­‰å¾…èœå•å±•å¼€
        self.log("æ­¥éª¤2: ç­‰å¾…äºŒçº§èœå•å±•å¼€...")
        time.sleep(1.0)
        
        # æŸ¥æ‰¾æœªå®Œæˆè¯¾ç¨‹
        self.log("æ­¥éª¤3: æˆªå›¾å¹¶åˆ†æå­¦æ—¶ä¿¡æ¯")
        incomplete_courses, all_courses = self.find_incomplete_courses(menu_id)
        
        if not incomplete_courses:
            self.log("   âœ… æ‰€æœ‰è¯¾ç¨‹å·²å®Œæˆæˆ–æœªæ£€æµ‹åˆ°è¯¾ç¨‹")
            return 0
        
        # ç‚¹å‡»æœªå®Œæˆè¯¾ç¨‹
        self.log(f"æ­¥éª¤4: å¤„ç† {len(incomplete_courses)} ä¸ªæœªå®Œæˆè¯¾ç¨‹")
        
        for i, course in enumerate(incomplete_courses):
            self.log(f"\n   >>> å­¦ä¹ è¯¾ç¨‹: {course['text']}")
            
            # æ‰¾åˆ°è¿™ä¸ªè¯¾ç¨‹åœ¨åˆ—è¡¨ä¸­çš„ç´¢å¼•
            course_index = all_courses.index(course)
            
            # ç‚¹å‡»è¯¾ç¨‹
            self.click_incomplete_course(menu_id, course_index, all_courses)
            
            # ç­‰å¾…è§†é¢‘å¼€å§‹æ’­æ”¾
            self.log("   ç­‰å¾…è§†é¢‘åŠ è½½...")
            time.sleep(3)
            
            # è¿™é‡Œå¯ä»¥æ·»åŠ ç­‰å¾…è§†é¢‘æ’­æ”¾å®Œæˆçš„é€»è¾‘
            # ç®€åŒ–ç‰ˆï¼šå›ºå®šç­‰å¾…æ—¶é—´
            video_duration = int(course['total'] * 60)  # å‡è®¾1å­¦æ—¶=60ç§’
            self.log(f"   é¢„è®¡å­¦ä¹ æ—¶é•¿: {video_duration} ç§’")
            
            # TODO: å®é™…åº”ç”¨ä¸­å¯ä»¥é€šè¿‡æˆªå›¾æ£€æµ‹æ’­æ”¾å®Œæˆ
            # time.sleep(video_duration)
            
            self.log("   â­ï¸  è·³è¿‡ç­‰å¾…ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰")
            
            # è¿”å›åˆ—è¡¨
            pyautogui.press('esc')
            time.sleep(1)
        
        return len(incomplete_courses)
    
    def run(self, menu_ids=None, test_mode=False):
        """è¿è¡Œè‡ªåŠ¨å­¦ä¹ """
        self.log("=" * 60)
        self.log("ğŸ“ è‡ªåŠ¨å­¦ä¹ æœºå™¨äººå¯åŠ¨")
        self.log("=" * 60)
        
        # æ£€æŸ¥OCR
        if not HAS_OCR:
            self.log("âš ï¸  è­¦å‘Š: æœªå®‰è£…OCRåº“ï¼Œè¯†åˆ«å¯èƒ½ä¸å‡†ç¡®")
            self.log("   å»ºè®®å®‰è£…: pip install pytesseract")
            self.log("   å¹¶å®‰è£…ç³»ç»Ÿä¾èµ–: sudo apt-get install tesseract-ocr tesseract-ocr-chi-sim")
        
        # æŸ¥æ‰¾çª—å£
        if not self.find_window():
            self.log("âŒ æ— æ³•æ‰¾åˆ°çª—å£ï¼Œç¨‹åºé€€å‡º")
            return
        
        # ç¡®å®šè¦å¤„ç†çš„èœå•
        if menu_ids is None:
            menu_ids = [1, 2, 3, 4]  # å¤„ç†æ‰€æœ‰èœå•
        
        self.log(f"\nå°†å¤„ç† {len(menu_ids)} ä¸ªèœå•: {menu_ids}")
        
        if test_mode:
            self.log("âš ï¸  æµ‹è¯•æ¨¡å¼ï¼šä¸ä¼šå®é™…ç­‰å¾…è§†é¢‘æ’­æ”¾")
        
        self.log("\nå‡†å¤‡å¼€å§‹... 3ç§’åå¯åŠ¨")
        time.sleep(3)
        
        # å¤„ç†æ¯ä¸ªèœå•
        total_processed = 0
        
        for menu_id in menu_ids:
            try:
                count = self.process_level1_menu(menu_id)
                total_processed += count
                
                # èœå•ä¹‹é—´çš„é—´éš”
                time.sleep(2)
                
            except KeyboardInterrupt:
                self.log("\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
                break
            except Exception as e:
                self.log(f"âŒ å¤„ç†èœå• {menu_id} æ—¶å‡ºé”™: {e}")
                import traceback
                self.log(traceback.format_exc())
                continue
        
        # å®Œæˆ
        self.log("\n" + "=" * 60)
        self.log("âœ… è‡ªåŠ¨å­¦ä¹ å®Œæˆ")
        self.log(f"   å¤„ç†äº† {total_processed} ä¸ªæœªå®Œæˆè¯¾ç¨‹")
        self.log(f"   æ—¥å¿—æ–‡ä»¶: {self.log_file}")
        self.log("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='è‡ªåŠ¨å­¦ä¹ æœºå™¨äºº')
    parser.add_argument('--menu', type=int, nargs='+', 
                       help='æŒ‡å®šè¦å¤„ç†çš„èœå•ID (1-4)ï¼Œé»˜è®¤å¤„ç†æ‰€æœ‰')
    parser.add_argument('--test', action='store_true',
                       help='æµ‹è¯•æ¨¡å¼ï¼šä¸ç­‰å¾…è§†é¢‘æ’­æ”¾')
    parser.add_argument('--base-image', default='lists.png',
                       help='åŸºå‡†å›¾ç‰‡è·¯å¾„')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæœºå™¨äºº
    bot = AutoLearningBot(base_image=args.base_image)
    
    # è¿è¡Œ
    try:
        bot.run(menu_ids=args.menu, test_mode=args.test)
    except KeyboardInterrupt:
        print("\n\nç¨‹åºè¢«ç”¨æˆ·ç»ˆæ­¢")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()

