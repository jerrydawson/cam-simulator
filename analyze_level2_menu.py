#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äºŒçº§èœå•ç‰¹å¾åˆ†æå·¥å…·
ä¸“é—¨åˆ†æå±•å¼€åçš„è¯¾ç¨‹åˆ—è¡¨ï¼ˆäºŒçº§èœå•ï¼‰
"""

import cv2
import numpy as np
from PIL import Image
import json
import re

try:
    import pytesseract
    HAS_OCR = True
except ImportError:
    HAS_OCR = False


class Level2MenuAnalyzer:
    """äºŒçº§èœå•åˆ†æå™¨"""
    
    def __init__(self, image_path):
        self.image_path = image_path
        self.image = None
        self.level1_buttons = []
        self.level2_regions = []
        
    def load_image(self):
        """åŠ è½½å›¾ç‰‡"""
        self.image = cv2.imread(self.image_path)
        if self.image is None:
            raise ValueError(f"æ— æ³•åŠ è½½å›¾ç‰‡: {self.image_path}")
        
        height, width = self.image.shape[:2]
        print(f"âœ… å›¾ç‰‡å·²åŠ è½½: {width}x{height}")
        return self.image
    
    def detect_level1_buttons(self):
        """æ£€æµ‹ä¸€çº§èœå•æŒ‰é’®"""
        print("\nğŸ”´ æ£€æµ‹ä¸€çº§èœå•æŒ‰é’®ï¼ˆçº¢è‰²ï¼‰")
        print("-" * 60)
        
        hsv = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)
        
        # çº¢è‰²èŒƒå›´
        lower_red1 = np.array([0, 100, 100])
        upper_red1 = np.array([10, 255, 255])
        lower_red2 = np.array([160, 100, 100])
        upper_red2 = np.array([180, 255, 255])
        
        mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
        mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
        red_mask = cv2.bitwise_or(mask1, mask2)
        
        contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        buttons = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 500:
                x, y, w, h = cv2.boundingRect(contour)
                if w > 30 and h > 30:
                    buttons.append({
                        'id': len(buttons) + 1,
                        'x': x,
                        'y': y,
                        'width': w,
                        'height': h,
                        'center_y': y + h // 2,
                        'area': int(area)
                    })
        
        buttons.sort(key=lambda b: b['y'])
        
        # å»é‡
        unique_buttons = []
        for btn in buttons:
            is_duplicate = False
            for existing in unique_buttons:
                if abs(btn['center_y'] - existing['center_y']) < 50:
                    is_duplicate = True
                    break
            if not is_duplicate:
                unique_buttons.append(btn)
        
        self.level1_buttons = unique_buttons
        
        print(f"   æ‰¾åˆ° {len(unique_buttons)} ä¸ªä¸€çº§èœå•æŒ‰é’®")
        for btn in unique_buttons:
            print(f"   æŒ‰é’® {btn['id']}: Y={btn['center_y']}")
        
        return unique_buttons
    
    def estimate_level2_regions(self):
        """ä¼°è®¡äºŒçº§èœå•åŒºåŸŸ"""
        print("\nğŸ“‹ ä¼°è®¡äºŒçº§èœå•åŒºåŸŸ")
        print("-" * 60)
        
        if not self.level1_buttons:
            self.detect_level1_buttons()
        
        height = self.image.shape[0]
        
        regions = []
        
        for i, btn in enumerate(self.level1_buttons):
            # äºŒçº§èœå•åœ¨ä¸€çº§æŒ‰é’®ä¸‹æ–¹
            y_start = btn['y'] + btn['height'] + 5
            
            # ç¡®å®šç»“æŸä½ç½®
            if i + 1 < len(self.level1_buttons):
                y_end = self.level1_buttons[i + 1]['y'] - 5
            else:
                y_end = height - 100
            
            region_height = y_end - y_start
            
            if region_height > 40:
                # ä¼°è®¡è¯¾ç¨‹æ•°é‡ï¼ˆå‡è®¾æ¯ä¸ªè¯¾ç¨‹çº¦45-70pxé«˜ï¼‰
                avg_item_height = 55
                estimated_items = max(1, int(region_height / avg_item_height))
                
                region = {
                    'parent_button': btn['id'],
                    'x': 20,
                    'y_start': y_start,
                    'y_end': y_end,
                    'height': region_height,
                    'estimated_items': estimated_items
                }
                
                regions.append(region)
                
                print(f"\n   ä¸€çº§æŒ‰é’® {btn['id']} çš„äºŒçº§èœå•:")
                print(f"      YèŒƒå›´: {y_start} ~ {y_end}")
                print(f"      é«˜åº¦: {region_height}px")
                print(f"      ä¼°è®¡è¯¾ç¨‹æ•°: {estimated_items}")
        
        self.level2_regions = regions
        return regions
    
    def analyze_level2_items(self):
        """åˆ†æäºŒçº§èœå•é¡¹çš„ç‰¹å¾"""
        print("\nğŸ” åˆ†æäºŒçº§èœå•é¡¹ç‰¹å¾")
        print("-" * 60)
        
        if not self.level2_regions:
            self.estimate_level2_regions()
        
        all_items = []
        
        for region in self.level2_regions:
            print(f"\n   === ä¸€çº§æŒ‰é’® {region['parent_button']} çš„äºŒçº§èœå• ===")
            
            # æå–è¯¥åŒºåŸŸ
            y_start = region['y_start']
            y_end = region['y_end']
            roi = self.image[y_start:y_end, :]
            
            # åˆ†æè¯¥åŒºåŸŸçš„ç‰¹å¾
            items = self.detect_items_in_region(roi, y_start, region['parent_button'])
            
            all_items.extend(items)
            
            print(f"      å®é™…æ£€æµ‹åˆ°: {len(items)} ä¸ªè¯¾ç¨‹é¡¹")
            
            for item in items[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"         è¯¾ç¨‹ {item['item_id']}: Y={item['y']}, é«˜åº¦={item['height']}px")
        
        print(f"\n   æ€»è®¡: {len(all_items)} ä¸ªäºŒçº§èœå•é¡¹")
        
        return all_items
    
    def detect_items_in_region(self, roi, offset_y, parent_id):
        """æ£€æµ‹åŒºåŸŸå†…çš„è¯¾ç¨‹é¡¹"""
        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        
        # ä½¿ç”¨MSERæ£€æµ‹æ–‡æœ¬åŒºåŸŸ
        mser = cv2.MSER_create()
        try:
            regions, _ = mser.detectRegions(gray)
        except:
            return []
        
        # ç­›é€‰è¯¾ç¨‹é¡¹
        items = []
        processed_y = set()
        
        for region in regions:
            if len(region) < 20:
                continue
            
            x, y, w, h = cv2.boundingRect(region)
            
            # è¯¾ç¨‹é¡¹ç‰¹å¾ï¼š
            # - å®½åº¦è¾ƒå¤§ï¼ˆåŒ…å«è¯¾ç¨‹åå’Œå­¦æ—¶ï¼‰
            # - é«˜åº¦é€‚ä¸­ï¼ˆ30-70pxï¼‰
            # - æ¨ªè·¨å¤šåˆ—
            if w > 200 and 30 < h < 70:
                # æ£€æŸ¥Yåæ ‡æ˜¯å¦å·²å¤„ç†ï¼ˆå»é‡ï¼‰
                y_key = y // 20  # 20pxå®¹å·®
                if y_key not in processed_y:
                    processed_y.add(y_key)
                    
                    items.append({
                        'parent_menu': parent_id,
                        'item_id': len(items) + 1,
                        'x': x,
                        'y': offset_y + y,
                        'width': w,
                        'height': h,
                        'center_y': offset_y + y + h // 2
                    })
        
        # æŒ‰Yåæ ‡æ’åº
        items.sort(key=lambda i: i['y'])
        
        # é‡æ–°ç¼–å·
        for i, item in enumerate(items):
            item['item_id'] = i + 1
        
        return items
    
    def detect_hours_text_positions(self):
        """æ£€æµ‹å­¦æ—¶æ–‡æœ¬çš„ä½ç½®"""
        print("\nâ° æ£€æµ‹å­¦æ—¶æ–‡æœ¬ä½ç½®")
        print("-" * 60)
        
        if not HAS_OCR:
            print("   âš ï¸  pytesseractæœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡å¼åŒ¹é…")
            return self.detect_hours_by_pattern()
        
        # å¯¹æ¯ä¸ªäºŒçº§åŒºåŸŸè¿›è¡ŒOCR
        hours_positions = []
        
        for region in self.level2_regions:
            y_start = region['y_start']
            y_end = region['y_end']
            
            # æå–åŒºåŸŸ
            roi = self.image[y_start:y_end, :]
            
            # OCRè¯†åˆ«
            try:
                # ä½¿ç”¨å›¾åƒåˆ°æ•°æ®ï¼Œè·å–ä½ç½®ä¿¡æ¯
                import pytesseract
                from pytesseract import Output
                
                data = pytesseract.image_to_data(roi, lang='chi_sim', output_type=Output.DICT)
                
                # æŸ¥æ‰¾å­¦æ—¶æ–‡æœ¬
                for i, text in enumerate(data['text']):
                    if not text.strip():
                        continue
                    
                    # åŒ¹é…å­¦æ—¶æ¨¡å¼
                    pattern = r'(\d+\.?\d*)/(\d+\.?\d*)å­¦æ—¶'
                    if re.search(pattern, text):
                        x = data['left'][i]
                        y = data['top'][i]
                        w = data['width'][i]
                        h = data['height'][i]
                        conf = data['conf'][i]
                        
                        if int(conf) > 30:  # ç½®ä¿¡åº¦é˜ˆå€¼
                            hours_positions.append({
                                'parent_menu': region['parent_button'],
                                'text': text,
                                'x': x,
                                'y': y_start + y,
                                'width': w,
                                'height': h,
                                'confidence': int(conf)
                            })
            except Exception as e:
                print(f"   OCRé”™è¯¯: {e}")
        
        print(f"   æ‰¾åˆ° {len(hours_positions)} ä¸ªå­¦æ—¶æ–‡æœ¬")
        
        for i, pos in enumerate(hours_positions[:5]):
            print(f"      {i+1}. {pos['text']} at ({pos['x']}, {pos['y']})")
        
        return hours_positions
    
    def detect_hours_by_pattern(self):
        """é€šè¿‡æ¨¡å¼æ£€æµ‹å­¦æ—¶æ–‡æœ¬ï¼ˆä¸ä½¿ç”¨OCRï¼‰"""
        # åŸºäºé¢œè‰²å’Œä½ç½®ç‰¹å¾ä¼°è®¡å­¦æ—¶æ–‡æœ¬ä½ç½®
        hours_positions = []
        
        for region in self.level2_regions:
            # å­¦æ—¶æ–‡æœ¬é€šå¸¸åœ¨å·¦ä¾§æˆ–ä¸­é—´
            # å‡è®¾æ¯ä¸ªè¯¾ç¨‹é¡¹çº¦55pxé«˜
            y_start = region['y_start']
            num_items = region['estimated_items']
            
            for i in range(num_items):
                item_y = y_start + 30 + i * 55
                
                if item_y < region['y_end']:
                    hours_positions.append({
                        'parent_menu': region['parent_button'],
                        'estimated': True,
                        'x': 150,  # ä¼°è®¡ä½ç½®
                        'y': item_y,
                        'click_x': 200,
                        'click_y': item_y
                    })
        
        print(f"   ä¼°è®¡ {len(hours_positions)} ä¸ªå­¦æ—¶æ–‡æœ¬ä½ç½®")
        
        return hours_positions
    
    def analyze_text_color(self):
        """åˆ†ææ–‡æœ¬é¢œè‰²ç‰¹å¾"""
        print("\nğŸ¨ åˆ†ææ–‡æœ¬é¢œè‰²")
        print("-" * 60)
        
        hsv = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)
        
        # å¸¸è§æ–‡æœ¬é¢œè‰²
        color_ranges = {
            'é»‘è‰²/æ·±ç°': ([0, 0, 0], [180, 255, 80]),
            'è“è‰²': ([100, 50, 50], [130, 255, 255]),
            'ç»¿è‰²': ([40, 50, 50], [80, 255, 255]),
        }
        
        for color_name, (lower, upper) in color_ranges.items():
            mask = cv2.inRange(hsv, np.array(lower), np.array(upper))
            pixels = cv2.countNonZero(mask)
            percentage = (pixels / (self.image.shape[0] * self.image.shape[1])) * 100
            
            if percentage > 1:
                print(f"   {color_name}: {percentage:.1f}%")
    
    def create_level2_visualization(self):
        """åˆ›å»ºäºŒçº§èœå•å¯è§†åŒ–"""
        print("\nğŸ¨ ç”ŸæˆäºŒçº§èœå•å¯è§†åŒ–")
        print("-" * 60)
        
        result = self.image.copy()
        
        # ç»˜åˆ¶ä¸€çº§æŒ‰é’®
        for btn in self.level1_buttons:
            cv2.rectangle(result,
                         (btn['x'], btn['y']),
                         (btn['x'] + btn['width'], btn['y'] + btn['height']),
                         (0, 0, 255), 3)
            cv2.putText(result, f"L1-{btn['id']}", 
                       (btn['x'] - 60, btn['y'] + btn['height'] // 2),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        # ç»˜åˆ¶äºŒçº§èœå•åŒºåŸŸ
        colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0)]
        
        for i, region in enumerate(self.level2_regions):
            color = colors[i % len(colors)]
            
            # ç»˜åˆ¶åŒºåŸŸè¾¹ç•Œ
            cv2.rectangle(result,
                         (10, region['y_start']),
                         (self.image.shape[1] - 10, region['y_end']),
                         color, 2)
            
            # æ ‡æ³¨
            cv2.putText(result, f"L2-Menu{region['parent_button']} ({region['estimated_items']} items)", 
                       (20, region['y_start'] + 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            
            # ç»˜åˆ¶ä¼°è®¡çš„è¯¾ç¨‹é¡¹ä½ç½®
            for j in range(region['estimated_items']):
                item_y = region['y_start'] + 30 + j * 55
                if item_y < region['y_end']:
                    # è¯¾ç¨‹é¡¹æ ‡è®°
                    cv2.circle(result, (50, item_y), 5, color, -1)
                    cv2.line(result, (50, item_y), (800, item_y), color, 1, cv2.LINE_AA)
                    
                    # å­¦æ—¶æ–‡æœ¬ä½ç½®æ ‡è®°
                    cv2.circle(result, (200, item_y), 8, (0, 165, 255), -1)
        
        # æ·»åŠ å›¾ä¾‹
        legend_y = 30
        cv2.putText(result, "Red box: L1 Menu | Colored box: L2 Region | Orange dot: Hours text", 
                   (10, legend_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        output_path = 'level2_menu_analyzed.png'
        cv2.imwrite(output_path, result)
        print(f"   âœ… ä¿å­˜: {output_path}")
        
        return output_path
    
    def generate_level2_report(self):
        """ç”ŸæˆäºŒçº§èœå•æŠ¥å‘Š"""
        print("\nğŸ“Š ç”ŸæˆäºŒçº§èœå•æŠ¥å‘Š")
        print("-" * 60)
        
        # åˆ†æäºŒçº§èœå•é¡¹
        level2_items = self.analyze_level2_items()
        
        # æ£€æµ‹å­¦æ—¶æ–‡æœ¬
        hours_positions = self.detect_hours_text_positions()
        
        report = {
            'image': {
                'path': self.image_path,
                'width': self.image.shape[1],
                'height': self.image.shape[0]
            },
            'level1_buttons': len(self.level1_buttons),
            'level2_regions': [
                {
                    'parent_button': r['parent_button'],
                    'y_start': int(r['y_start']),
                    'y_end': int(r['y_end']),
                    'height': int(r['height']),
                    'estimated_items': r['estimated_items']
                }
                for r in self.level2_regions
            ],
            'level2_items': [
                {
                    'parent_menu': item['parent_menu'],
                    'item_id': item['item_id'],
                    'y': int(item['y']),
                    'height': int(item['height']),
                    'estimated_click_y': int(item['center_y'])
                }
                for item in level2_items
            ],
            'hours_text_positions': hours_positions,
            'statistics': {
                'total_level2_items': len(level2_items),
                'total_hours_detected': len(hours_positions),
                'avg_item_height': int(np.mean([item['height'] for item in level2_items])) if level2_items else 0
            },
            'recommendations': [
                {
                    'type': 'äºŒçº§èœå•å®šä½',
                    'suggestion': f'äºŒçº§èœå•å¹³å‡{np.mean([r["height"] for r in self.level2_regions]):.0f}pxé«˜ï¼Œæ¯ä¸ªè¯¾ç¨‹é¡¹çº¦55px',
                    'confidence': 'high'
                },
                {
                    'type': 'å­¦æ—¶æ–‡æœ¬ä½ç½®',
                    'suggestion': 'å­¦æ—¶æ–‡æœ¬é€šå¸¸åœ¨X=150-250èŒƒå›´ï¼Œå»ºè®®å…ˆåœ¨æ­¤èŒƒå›´æœç´¢',
                    'confidence': 'medium'
                },
                {
                    'type': 'ç‚¹å‡»ç­–ç•¥',
                    'suggestion': 'å…ˆç‚¹å‡»ä¸€çº§èœå•å±•å¼€ï¼Œç­‰å¾…0.5-1ç§’ï¼Œç„¶ååœ¨äºŒçº§åŒºåŸŸæœç´¢å­¦æ—¶æ–‡æœ¬',
                    'confidence': 'high'
                }
            ]
        }
        
        json_path = 'level2_menu_report.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"   âœ… ä¿å­˜: {json_path}")
        
        return report
    
    def print_summary(self):
        """æ‰“å°æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“Š äºŒçº§èœå•åˆ†ææ‘˜è¦")
        print("=" * 60)
        
        print(f"\nä¸€çº§èœå•:")
        print(f"  æŒ‰é’®æ•°é‡: {len(self.level1_buttons)}")
        
        print(f"\näºŒçº§èœå•:")
        print(f"  åŒºåŸŸæ•°é‡: {len(self.level2_regions)}")
        
        total_items = sum(r['estimated_items'] for r in self.level2_regions)
        print(f"  ä¼°è®¡è¯¾ç¨‹æ€»æ•°: {total_items}")
        
        if self.level2_regions:
            avg_height = np.mean([r['height'] for r in self.level2_regions])
            print(f"  å¹³å‡åŒºåŸŸé«˜åº¦: {avg_height:.0f}px")
        
        print("\nå…³é”®å‚æ•°:")
        print("  æ¯ä¸ªè¯¾ç¨‹é¡¹é«˜åº¦: çº¦55px")
        print("  å­¦æ—¶æ–‡æœ¬Xä½ç½®: çº¦150-250")
        print("  ç‚¹å‡»ç­‰å¾…æ—¶é—´: 0.5-1ç§’")
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("=" * 60)
        print("ğŸ“ äºŒçº§èœå•ç‰¹å¾åˆ†æ")
        print("=" * 60)
        
        self.load_image()
        self.detect_level1_buttons()
        self.estimate_level2_regions()
        self.analyze_text_color()
        
        self.create_level2_visualization()
        report = self.generate_level2_report()
        
        self.print_summary()
        
        return report


def main():
    import sys
    
    image_path = 'lists_full.png' if len(sys.argv) < 2 else sys.argv[1]
    
    analyzer = Level2MenuAnalyzer(image_path)
    analyzer.run_analysis()
    
    print("\n" + "=" * 60)
    print("âœ… äºŒçº§èœå•åˆ†æå®Œæˆ!")
    print("=" * 60)
    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    print("  level2_menu_analyzed.png  - äºŒçº§èœå•å¯è§†åŒ–")
    print("  level2_menu_report.json   - è¯¦ç»†åˆ†ææŠ¥å‘Š")


if __name__ == '__main__':
    main()

