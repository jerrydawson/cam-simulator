#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›¾ç‰‡ç‰¹å¾åˆ†æå·¥å…·
åˆ†ælists_full.pngï¼Œè¯†åˆ«å…³é”®ç‰¹å¾ä»¥æé«˜è¯†åˆ«å‡†ç¡®ç‡
"""

import cv2
import numpy as np
from PIL import Image
import json
import re


class FeatureAnalyzer:
    def __init__(self, image_path):
        self.image_path = image_path
        self.image = None
        self.gray = None
        self.features = {}
        
    def load_image(self):
        """åŠ è½½å›¾ç‰‡"""
        self.image = cv2.imread(self.image_path)
        if self.image is None:
            raise ValueError(f"æ— æ³•åŠ è½½å›¾ç‰‡: {self.image_path}")
        
        self.gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)
        height, width = self.image.shape[:2]
        
        print(f"âœ… å›¾ç‰‡å·²åŠ è½½: {width}x{height}")
        return self.image
    
    def analyze_colors(self):
        """åˆ†æé¢œè‰²ç‰¹å¾"""
        print("\nğŸ¨ é¢œè‰²ç‰¹å¾åˆ†æ")
        print("-" * 60)
        
        hsv = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)
        
        # å®šä¹‰é¢œè‰²èŒƒå›´
        color_ranges = {
            'çº¢è‰²': ([0, 100, 100], [10, 255, 255], [160, 100, 100], [180, 255, 255]),
            'æ©™è‰²': ([10, 100, 100], [25, 255, 255], None, None),
            'é»„è‰²': ([25, 100, 100], [35, 255, 255], None, None),
            'ç»¿è‰²': ([35, 100, 100], [85, 255, 255], None, None),
            'è“è‰²': ([85, 100, 100], [125, 255, 255], None, None),
            'ç´«è‰²': ([125, 100, 100], [160, 255, 255], None, None),
        }
        
        color_stats = {}
        
        for color_name, ranges in color_ranges.items():
            if ranges[2] is not None:  # çº¢è‰²æœ‰ä¸¤ä¸ªèŒƒå›´
                mask1 = cv2.inRange(hsv, np.array(ranges[0]), np.array(ranges[1]))
                mask2 = cv2.inRange(hsv, np.array(ranges[2]), np.array(ranges[3]))
                mask = cv2.bitwise_or(mask1, mask2)
            else:
                mask = cv2.inRange(hsv, np.array(ranges[0]), np.array(ranges[1]))
            
            # è®¡ç®—é¢œè‰²å æ¯”
            color_pixels = cv2.countNonZero(mask)
            total_pixels = self.image.shape[0] * self.image.shape[1]
            percentage = (color_pixels / total_pixels) * 100
            
            if percentage > 0.1:  # åªæ˜¾ç¤ºå æ¯”è¶…è¿‡0.1%çš„é¢œè‰²
                color_stats[color_name] = {
                    'pixels': int(color_pixels),
                    'percentage': round(percentage, 2)
                }
                print(f"   {color_name}: {color_pixels} åƒç´  ({percentage:.2f}%)")
                
                # æŸ¥æ‰¾è¯¥é¢œè‰²çš„è½®å»“
                contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                large_contours = [c for c in contours if cv2.contourArea(c) > 200]
                
                if large_contours:
                    print(f"      æ£€æµ‹åˆ° {len(large_contours)} ä¸ª{color_name}åŒºåŸŸ")
        
        self.features['colors'] = color_stats
        return color_stats
    
    def analyze_text_regions(self):
        """åˆ†ææ–‡æœ¬åŒºåŸŸç‰¹å¾"""
        print("\nğŸ“ æ–‡æœ¬åŒºåŸŸåˆ†æ")
        print("-" * 60)
        
        # ä½¿ç”¨MSERæ£€æµ‹æ–‡æœ¬åŒºåŸŸ
        mser = cv2.MSER_create()
        regions, _ = mser.detectRegions(self.gray)
        
        # ç­›é€‰æ–‡æœ¬åŒºåŸŸ
        text_regions = []
        for region in regions:
            if len(region) < 10:
                continue
            
            x, y, w, h = cv2.boundingRect(region)
            
            # æ–‡æœ¬ç‰¹å¾ï¼šå®½åº¦>é«˜åº¦ï¼Œé«˜åº¦åœ¨åˆç†èŒƒå›´
            aspect_ratio = w / h if h > 0 else 0
            
            if 15 < h < 60 and 2 < aspect_ratio < 20:
                text_regions.append({
                    'x': int(x),
                    'y': int(y),
                    'width': int(w),
                    'height': int(h),
                    'aspect_ratio': round(aspect_ratio, 2)
                })
        
        print(f"   æ£€æµ‹åˆ° {len(text_regions)} ä¸ªæ–‡æœ¬åŒºåŸŸ")
        
        # æŒ‰Yåæ ‡åˆ†ç»„ï¼ˆåŒä¸€è¡Œçš„æ–‡æœ¬ï¼‰
        text_regions.sort(key=lambda r: r['y'])
        
        lines = []
        current_line = []
        last_y = -1
        
        for region in text_regions:
            if last_y == -1 or abs(region['y'] - last_y) < 20:
                current_line.append(region)
            else:
                if current_line:
                    lines.append(current_line)
                current_line = [region]
            last_y = region['y']
        
        if current_line:
            lines.append(current_line)
        
        print(f"   ä¼°è®¡æœ‰ {len(lines)} è¡Œæ–‡æœ¬")
        
        # åˆ†ææ–‡æœ¬é«˜åº¦åˆ†å¸ƒ
        heights = [r['height'] for r in text_regions]
        if heights:
            avg_height = np.mean(heights)
            std_height = np.std(heights)
            print(f"   å¹³å‡æ–‡æœ¬é«˜åº¦: {avg_height:.1f}px (Â±{std_height:.1f})")
        
        self.features['text_regions'] = {
            'total': len(text_regions),
            'lines': len(lines),
            'avg_height': round(float(avg_height), 1) if heights else 0
        }
        
        return text_regions
    
    def detect_buttons_and_icons(self):
        """æ£€æµ‹æŒ‰é’®å’Œå›¾æ ‡"""
        print("\nğŸ”˜ æŒ‰é’®å’Œå›¾æ ‡æ£€æµ‹")
        print("-" * 60)
        
        # è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(self.gray, 50, 150)
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        buttons = []
        
        for contour in contours:
            area = cv2.contourArea(contour)
            if area < 200 or area > 10000:
                continue
            
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = w / h if h > 0 else 0
            
            # æŒ‰é’®ç‰¹å¾ï¼šæ¥è¿‘æ­£æ–¹å½¢æˆ–å°çŸ©å½¢
            if 0.5 < aspect_ratio < 2.5 and 20 < w < 200 and 20 < h < 80:
                buttons.append({
                    'x': int(x),
                    'y': int(y),
                    'width': int(w),
                    'height': int(h),
                    'area': int(area),
                    'aspect_ratio': round(aspect_ratio, 2)
                })
        
        # æŒ‰Yåæ ‡æ’åº
        buttons.sort(key=lambda b: b['y'])
        
        print(f"   æ£€æµ‹åˆ° {len(buttons)} ä¸ªå¯èƒ½çš„æŒ‰é’®/å›¾æ ‡")
        
        # æŒ‰Xåæ ‡åˆ†ç»„ï¼ˆå·¦ä¾§ã€ä¸­é—´ã€å³ä¾§ï¼‰
        width = self.image.shape[1]
        left_buttons = [b for b in buttons if b['x'] < width * 0.3]
        center_buttons = [b for b in buttons if width * 0.3 <= b['x'] < width * 0.7]
        right_buttons = [b for b in buttons if b['x'] >= width * 0.7]
        
        print(f"   å·¦ä¾§: {len(left_buttons)} ä¸ª")
        print(f"   ä¸­é—´: {len(center_buttons)} ä¸ª")
        print(f"   å³ä¾§: {len(right_buttons)} ä¸ª")
        
        self.features['buttons'] = {
            'total': len(buttons),
            'left': len(left_buttons),
            'center': len(center_buttons),
            'right': len(right_buttons)
        }
        
        return buttons
    
    def detect_horizontal_lines(self):
        """æ£€æµ‹æ°´å¹³åˆ†éš”çº¿"""
        print("\nğŸ“ æ°´å¹³åˆ†éš”çº¿æ£€æµ‹")
        print("-" * 60)
        
        # ä½¿ç”¨å½¢æ€å­¦æ“ä½œæ£€æµ‹æ°´å¹³çº¿
        width = self.image.shape[1]
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (width // 2, 1))
        detect_horizontal = cv2.morphologyEx(self.gray, cv2.MORPH_CLOSE, horizontal_kernel)
        
        # è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(detect_horizontal, 50, 150)
        
        # éœå¤«å˜æ¢æ£€æµ‹ç›´çº¿
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, 
                                minLineLength=width//3, maxLineGap=20)
        
        horizontal_lines = []
        
        if lines is not None:
            for line in lines:
                x1, y1, x2, y2 = line[0]
                # åªä¿ç•™æ¥è¿‘æ°´å¹³çš„çº¿ï¼ˆè§’åº¦å°äº5åº¦ï¼‰
                if abs(y2 - y1) < 5:
                    horizontal_lines.append({
                        'y': int((y1 + y2) / 2),
                        'x1': int(x1),
                        'x2': int(x2),
                        'length': int(abs(x2 - x1))
                    })
        
        # å»é‡ï¼ˆYåæ ‡ç›¸è¿‘çš„åˆå¹¶ï¼‰
        horizontal_lines.sort(key=lambda l: l['y'])
        unique_lines = []
        
        for line in horizontal_lines:
            if not unique_lines or abs(line['y'] - unique_lines[-1]['y']) > 10:
                unique_lines.append(line)
        
        print(f"   æ£€æµ‹åˆ° {len(unique_lines)} æ¡æ°´å¹³åˆ†éš”çº¿")
        
        for i, line in enumerate(unique_lines[:10]):  # åªæ˜¾ç¤ºå‰10æ¡
            print(f"      çº¿{i+1}: Y={line['y']}, é•¿åº¦={line['length']}px")
        
        self.features['horizontal_lines'] = len(unique_lines)
        
        return unique_lines
    
    def detect_list_structure(self):
        """æ£€æµ‹åˆ—è¡¨ç»“æ„"""
        print("\nğŸ“‹ åˆ—è¡¨ç»“æ„åˆ†æ")
        print("-" * 60)
        
        # åŸºäºæ°´å¹³çº¿å’Œæ–‡æœ¬åŒºåŸŸæ¨æ–­åˆ—è¡¨ç»“æ„
        lines = self.detect_horizontal_lines()
        
        if len(lines) > 1:
            # è®¡ç®—è¡Œé—´è·
            spacings = []
            for i in range(len(lines) - 1):
                spacing = lines[i + 1]['y'] - lines[i]['y']
                spacings.append(spacing)
            
            if spacings:
                avg_spacing = np.mean(spacings)
                std_spacing = np.std(spacings)
                
                print(f"   å¹³å‡è¡Œé—´è·: {avg_spacing:.1f}px (Â±{std_spacing:.1f})")
                
                # ä¼°è®¡åˆ—è¡¨é¡¹æ•°é‡
                height = self.image.shape[0]
                estimated_items = int(height / avg_spacing)
                print(f"   ä¼°è®¡åˆ—è¡¨é¡¹æ•°é‡: {estimated_items}")
                
                self.features['list_structure'] = {
                    'avg_spacing': round(float(avg_spacing), 1),
                    'estimated_items': estimated_items
                }
    
    def detect_hours_pattern(self):
        """æ£€æµ‹å­¦æ—¶æ–‡æœ¬æ¨¡å¼"""
        print("\nâ° å­¦æ—¶æ–‡æœ¬æ¨¡å¼åˆ†æ")
        print("-" * 60)
        
        # å°è¯•OCRè¯†åˆ«ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            import pytesseract
            
            # å¯¹æ•´ä¸ªå›¾ç‰‡è¿›è¡ŒOCR
            text = pytesseract.image_to_string(self.image, lang='chi_sim')
            
            # æŸ¥æ‰¾å­¦æ—¶æ¨¡å¼
            pattern = r'(\d+\.?\d*)\s*/\s*(\d+\.?\d*)\s*å­¦æ—¶'
            matches = re.findall(pattern, text)
            
            if matches:
                print(f"   âœ… æ£€æµ‹åˆ° {len(matches)} ä¸ªå­¦æ—¶ä¿¡æ¯")
                
                hours_data = []
                for completed, total in matches:
                    try:
                        c = float(completed)
                        t = float(total)
                        is_incomplete = c < t
                        hours_data.append({
                            'completed': c,
                            'total': t,
                            'incomplete': is_incomplete,
                            'text': f"{c}/{t}å­¦æ—¶"
                        })
                    except:
                        pass
                
                # ç»Ÿè®¡
                incomplete_count = sum(1 for h in hours_data if h['incomplete'])
                complete_count = len(hours_data) - incomplete_count
                
                print(f"   æœªå®Œæˆ: {incomplete_count} ä¸ª")
                print(f"   å·²å®Œæˆ: {complete_count} ä¸ª")
                
                # æ˜¾ç¤ºå‰å‡ ä¸ª
                print(f"\n   ç¤ºä¾‹:")
                for i, h in enumerate(hours_data[:5]):
                    status = "âŒ" if h['incomplete'] else "âœ…"
                    print(f"      {i+1}. {h['text']} {status}")
                
                self.features['hours_pattern'] = {
                    'total': len(hours_data),
                    'incomplete': incomplete_count,
                    'complete': complete_count
                }
                
                return hours_data
            else:
                print("   âš ï¸  æœªæ£€æµ‹åˆ°å­¦æ—¶ä¿¡æ¯")
                
        except ImportError:
            print("   âš ï¸  pytesseractæœªå®‰è£…ï¼Œè·³è¿‡OCRåˆ†æ")
        except Exception as e:
            print(f"   âš ï¸  OCRé”™è¯¯: {e}")
        
        return []
    
    def analyze_layout(self):
        """åˆ†ææ•´ä½“å¸ƒå±€"""
        print("\nğŸ–¼ï¸  æ•´ä½“å¸ƒå±€åˆ†æ")
        print("-" * 60)
        
        height, width = self.image.shape[:2]
        
        # åˆ†æå‚ç›´å¯†åº¦ï¼ˆæ¯ä¸€è¡Œçš„åƒç´ å˜åŒ–ï¼‰
        row_variance = []
        for y in range(0, height, 10):  # æ¯10è¡Œé‡‡æ ·
            row = self.gray[y, :]
            variance = np.var(row)
            row_variance.append(variance)
        
        # æ‰¾å‡ºå†…å®¹å¯†é›†åŒºåŸŸï¼ˆæ–¹å·®å¤§çš„åŒºåŸŸï¼‰
        threshold = np.mean(row_variance)
        content_regions = []
        in_region = False
        region_start = 0
        
        for i, var in enumerate(row_variance):
            if var > threshold and not in_region:
                in_region = True
                region_start = i * 10
            elif var <= threshold and in_region:
                in_region = False
                content_regions.append((region_start, i * 10))
        
        print(f"   å›¾ç‰‡å°ºå¯¸: {width}x{height}")
        print(f"   å†…å®¹å¯†é›†åŒºåŸŸ: {len(content_regions)} ä¸ª")
        
        for i, (start, end) in enumerate(content_regions[:5]):
            print(f"      åŒºåŸŸ{i+1}: Y={start}~{end} (é«˜åº¦: {end-start}px)")
        
        self.features['layout'] = {
            'width': width,
            'height': height,
            'content_regions': len(content_regions)
        }
    
    def create_visualization(self):
        """åˆ›å»ºå¯è§†åŒ–ç‰¹å¾å›¾"""
        print("\nğŸ¨ ç”Ÿæˆç‰¹å¾å¯è§†åŒ–å›¾...")
        
        result = self.image.copy()
        height, width = result.shape[:2]
        
        # ç»˜åˆ¶é¢œè‰²åŒºåŸŸ
        hsv = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)
        
        # çº¢è‰²åŒºåŸŸï¼ˆä¸€çº§èœå•æŒ‰é’®ï¼‰
        lower_red1 = np.array([0, 100, 100])
        upper_red1 = np.array([10, 255, 255])
        lower_red2 = np.array([160, 100, 100])
        upper_red2 = np.array([180, 255, 255])
        
        mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
        mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
        red_mask = cv2.bitwise_or(mask1, mask2)
        
        contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 500:
                x, y, w, h = cv2.boundingRect(contour)
                cv2.rectangle(result, (x, y), (x+w, y+h), (0, 0, 255), 3)
                cv2.putText(result, "Level1", (x-60, y+h//2),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        # æ·»åŠ æ ‡æ³¨
        cv2.putText(result, f"Size: {width}x{height}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        # ä¿å­˜
        output_path = 'features_analyzed.png'
        cv2.imwrite(output_path, result)
        print(f"   âœ… ä¿å­˜: {output_path}")
        
        return output_path
    
    def generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        report = {
            'image': {
                'path': self.image_path,
                'width': int(self.image.shape[1]),
                'height': int(self.image.shape[0])
            },
            'features': self.features,
            'recommendations': self.generate_recommendations()
        }
        
        # ä¿å­˜JSON
        json_path = 'features_report.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"   âœ… ä¿å­˜: {json_path}")
        
        return report
    
    def generate_recommendations(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # åŸºäºé¢œè‰²ç‰¹å¾
        if 'colors' in self.features:
            if 'çº¢è‰²' in self.features['colors']:
                recommendations.append({
                    'type': 'é¢œè‰²è¯†åˆ«',
                    'suggestion': 'ä½¿ç”¨çº¢è‰²HSVèŒƒå›´([0,100,100]-[10,255,255])è¯†åˆ«ä¸€çº§èœå•æŒ‰é’®',
                    'confidence': 'high'
                })
        
        # åŸºäºæ–‡æœ¬åŒºåŸŸ
        if 'text_regions' in self.features:
            avg_h = self.features['text_regions'].get('avg_height', 0)
            if avg_h > 0:
                recommendations.append({
                    'type': 'OCRä¼˜åŒ–',
                    'suggestion': f'æ–‡æœ¬é«˜åº¦çº¦{avg_h}pxï¼Œå»ºè®®OCRå‰é¢„å¤„ç†ï¼šç¼©æ”¾åˆ°ç»Ÿä¸€é«˜åº¦30-40px',
                    'confidence': 'medium'
                })
        
        # åŸºäºæŒ‰é’®åˆ†å¸ƒ
        if 'buttons' in self.features:
            right_buttons = self.features['buttons'].get('right', 0)
            if right_buttons > 0:
                recommendations.append({
                    'type': 'æŒ‰é’®å®šä½',
                    'suggestion': f'å³ä¾§æœ‰{right_buttons}ä¸ªæŒ‰é’®ï¼Œå»ºè®®ä¼˜å…ˆåœ¨å›¾ç‰‡å³ä¾§åŒºåŸŸæŸ¥æ‰¾èœå•æŒ‰é’®',
                    'confidence': 'high'
                })
        
        return recommendations
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("=" * 60)
        print("ğŸ” å›¾ç‰‡ç‰¹å¾åˆ†æ")
        print("=" * 60)
        
        self.load_image()
        self.analyze_colors()
        self.analyze_text_regions()
        self.detect_buttons_and_icons()
        self.detect_horizontal_lines()
        self.detect_list_structure()
        self.detect_hours_pattern()
        self.analyze_layout()
        
        self.create_visualization()
        report = self.generate_report()
        
        self.print_summary()
        
        return report
    
    def print_summary(self):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“Š åˆ†ææ‘˜è¦")
        print("=" * 60)
        
        print(f"\nå›¾ç‰‡ä¿¡æ¯:")
        print(f"  è·¯å¾„: {self.image_path}")
        print(f"  å°ºå¯¸: {self.image.shape[1]}x{self.image.shape[0]}")
        
        if self.features:
            print(f"\næ£€æµ‹åˆ°çš„ç‰¹å¾:")
            for key, value in self.features.items():
                print(f"  {key}: {value}")
        
        print("\nç”Ÿæˆçš„æ–‡ä»¶:")
        print("  features_analyzed.png  - å¯è§†åŒ–ç‰¹å¾å›¾")
        print("  features_report.json   - è¯¦ç»†åˆ†ææŠ¥å‘Š")


def main():
    import sys
    
    image_path = 'lists_full.png' if len(sys.argv) < 2 else sys.argv[1]
    
    analyzer = FeatureAnalyzer(image_path)
    analyzer.run_analysis()
    
    print("\n" + "=" * 60)
    print("âœ… åˆ†æå®Œæˆ!")
    print("=" * 60)


if __name__ == '__main__':
    main()

