#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–çš„è¯†åˆ«å™¨
åŸºäºç‰¹å¾åˆ†æç»“æœï¼Œæä¾›é«˜å‡†ç¡®ç‡çš„å…ƒç´ è¯†åˆ«
"""

import cv2
import numpy as np
from PIL import Image
import re

try:
    import pytesseract
    HAS_OCR = True
except ImportError:
    HAS_OCR = False


class OptimizedRecognizer:
    """
    ä¼˜åŒ–çš„è¯†åˆ«å™¨
    
    åŸºäºlists_full.pngçš„ç‰¹å¾åˆ†æï¼š
    - å›¾ç‰‡å°ºå¯¸: 866x2056
    - çº¢è‰²åŒºåŸŸ: 15ä¸ª (0.77%) - ä¸€çº§èœå•æŒ‰é’®
    - æ–‡æœ¬åŒºåŸŸ: 276ä¸ªï¼Œå¹³å‡é«˜åº¦19.5px
    - æ°´å¹³åˆ†éš”çº¿: 29æ¡ï¼Œå¹³å‡é—´è·69.1px
    - åˆ—è¡¨é¡¹: çº¦29ä¸ª
    """
    
    def __init__(self):
        # é¢œè‰²è¯†åˆ«å‚æ•°ï¼ˆHSVï¼‰
        self.color_ranges = {
            'çº¢è‰²': {
                'lower1': np.array([0, 100, 100]),
                'upper1': np.array([10, 255, 255]),
                'lower2': np.array([160, 100, 100]),
                'upper2': np.array([180, 255, 255]),
                'min_area': 500,
                'description': 'ä¸€çº§èœå•æŒ‰é’®'
            },
            'æ©™è‰²': {
                'lower': np.array([10, 100, 100]),
                'upper': np.array([25, 255, 255]),
                'min_area': 200,
                'description': 'åº•éƒ¨æŒ‰é’®'
            },
            'è“è‰²': {
                'lower': np.array([85, 100, 100]),
                'upper': np.array([125, 255, 255]),
                'min_area': 200,
                'description': 'é“¾æ¥æˆ–æç¤º'
            }
        }
        
        # æ–‡æœ¬è¯†åˆ«å‚æ•°
        self.text_config = {
            'avg_height': 19.5,
            'height_range': (15, 25),
            'aspect_ratio_range': (2, 20),
            'min_width': 80
        }
        
        # æŒ‰é’®è¯†åˆ«å‚æ•°
        self.button_config = {
            'min_area': 200,
            'max_area': 10000,
            'aspect_ratio_range': (0.5, 2.5),
            'width_range': (20, 200),
            'height_range': (20, 80)
        }
        
        # åˆ—è¡¨ç»“æ„å‚æ•°
        self.list_config = {
            'avg_spacing': 69.1,
            'spacing_tolerance': 20,
            'estimated_items': 29
        }
    
    def detect_red_buttons(self, image):
        """
        æ£€æµ‹çº¢è‰²æŒ‰é’®ï¼ˆä¸€çº§èœå•ï¼‰
        
        ä¼˜åŒ–ç‚¹ï¼š
        - ä½¿ç”¨ç²¾ç¡®çš„HSVèŒƒå›´
        - é¢ç§¯è¿‡æ»¤ï¼ˆ>500pxÂ²ï¼‰
        - å»é‡å¤„ç†
        """
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        # çº¢è‰²æœ‰ä¸¤ä¸ªHSVèŒƒå›´
        config = self.color_ranges['çº¢è‰²']
        mask1 = cv2.inRange(hsv, config['lower1'], config['upper1'])
        mask2 = cv2.inRange(hsv, config['lower2'], config['upper2'])
        red_mask = cv2.bitwise_or(mask1, mask2)
        
        # å½¢æ€å­¦å¤„ç†ï¼Œå»å™ª
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)
        red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel)
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        buttons = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area < config['min_area']:
                continue
            
            x, y, w, h = cv2.boundingRect(contour)
            
            # æŒ‰é’®ç‰¹å¾éªŒè¯
            if w < 30 or h < 30:
                continue
            
            buttons.append({
                'x': x,
                'y': y,
                'width': w,
                'height': h,
                'center_x': x + w // 2,
                'center_y': y + h // 2,
                'area': int(area),
                'type': 'level1_menu',
                'color': 'çº¢è‰²'
            })
        
        # æŒ‰Yåæ ‡æ’åº
        buttons.sort(key=lambda b: b['y'])
        
        # å»é‡ï¼ˆYåæ ‡ç›¸è¿‘çš„åˆå¹¶ï¼‰
        unique_buttons = []
        for btn in buttons:
            is_duplicate = False
            for existing in unique_buttons:
                if abs(btn['center_y'] - existing['center_y']) < 30 and \
                   abs(btn['center_x'] - existing['center_x']) < 30:
                    is_duplicate = True
                    break
            if not is_duplicate:
                unique_buttons.append(btn)
        
        return unique_buttons
    
    def extract_text_with_preprocessing(self, image, region):
        """
        å¸¦é¢„å¤„ç†çš„æ–‡æœ¬æå–
        
        ä¼˜åŒ–ç‚¹ï¼š
        - ç°åº¦åŒ–
        - å¯¹æ¯”åº¦å¢å¼º
        - äºŒå€¼åŒ–
        - é™å™ª
        - å°ºå¯¸å½’ä¸€åŒ–
        """
        if not HAS_OCR:
            return None
        
        x, y, w, h = region['x'], region['y'], region['width'], region['height']
        roi = image[y:y+h, x:x+w]
        
        # 1. ç°åº¦åŒ–
        if len(roi.shape) == 3:
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        else:
            gray = roi
        
        # 2. å¯¹æ¯”åº¦å¢å¼ºï¼ˆCLAHEï¼‰
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(gray)
        
        # 3. äºŒå€¼åŒ–
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # 4. é™å™ª
        denoised = cv2.fastNlMeansDenoising(binary, None, 10, 7, 21)
        
        # 5. å°ºå¯¸å½’ä¸€åŒ–ï¼ˆæ”¾å¤§åˆ°æ ‡å‡†é«˜åº¦ï¼‰
        target_height = 40
        scale = target_height / h
        new_width = int(w * scale)
        resized = cv2.resize(denoised, (new_width, target_height), interpolation=cv2.INTER_CUBIC)
        
        # 6. OCRè¯†åˆ«
        try:
            # é…ç½®ï¼šåªè¯†åˆ«æ•°å­—ã€æ–œæ ã€å°æ•°ç‚¹å’Œä¸­æ–‡
            custom_config = r'--oem 3 --psm 7 -c tessedit_char_whitelist=0123456789./å­¦æ—¶'
            text = pytesseract.image_to_string(resized, lang='chi_sim', config=custom_config)
            return text.strip()
        except Exception as e:
            return None
    
    def detect_hours_pattern(self, image, save_debug=False):
        """
        æ£€æµ‹å­¦æ—¶æ¨¡å¼
        
        ä¼˜åŒ–ç‚¹ï¼š
        - å…ˆæ£€æµ‹å¯èƒ½çš„æ–‡æœ¬åŒºåŸŸ
        - åªå¯¹æœ‰å¸Œæœ›çš„åŒºåŸŸè¿›è¡ŒOCR
        - ä½¿ç”¨æ­£åˆ™ç²¾ç¡®åŒ¹é…
        """
        if not HAS_OCR:
            return []
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ä½¿ç”¨MSERæ£€æµ‹æ–‡æœ¬åŒºåŸŸ
        mser = cv2.MSER_create()
        regions, _ = mser.detectRegions(gray)
        
        # ç­›é€‰å¯èƒ½åŒ…å«å­¦æ—¶ä¿¡æ¯çš„åŒºåŸŸ
        text_regions = []
        for region in regions:
            if len(region) < 10:
                continue
            
            x, y, w, h = cv2.boundingRect(region)
            
            # å­¦æ—¶æ–‡æœ¬ç‰¹å¾ï¼šå®½åº¦è¾ƒå¤§ï¼Œé«˜åº¦é€‚ä¸­
            cfg = self.text_config
            if cfg['height_range'][0] < h < cfg['height_range'][1] and w > cfg['min_width']:
                aspect_ratio = w / h
                if cfg['aspect_ratio_range'][0] < aspect_ratio < cfg['aspect_ratio_range'][1]:
                    text_regions.append({'x': x, 'y': y, 'width': w, 'height': h})
        
        # å»é‡ï¼ˆåˆå¹¶é‡å åŒºåŸŸï¼‰
        text_regions = self._merge_overlapping_regions(text_regions)
        
        # å¯¹æ¯ä¸ªåŒºåŸŸè¿›è¡ŒOCR
        hours_data = []
        debug_img = image.copy() if save_debug else None
        
        for i, region in enumerate(text_regions):
            text = self.extract_text_with_preprocessing(image, region)
            
            if text:
                # åŒ¹é…å­¦æ—¶æ¨¡å¼
                pattern = r'(\d+\.?\d*)\s*/\s*(\d+\.?\d*)\s*å­¦æ—¶'
                matches = re.findall(pattern, text)
                
                if matches:
                    for completed, total in matches:
                        try:
                            c = float(completed)
                            t = float(total)
                            
                            hours_data.append({
                                'completed': c,
                                'total': t,
                                'incomplete': c < t,
                                'text': f"{c}/{t}å­¦æ—¶",
                                'region': region,
                                'confidence': 'high'
                            })
                            
                            # è°ƒè¯•ï¼šæ ‡æ³¨è¯†åˆ«åˆ°çš„åŒºåŸŸ
                            if save_debug:
                                x, y, w, h = region['x'], region['y'], region['width'], region['height']
                                color = (0, 0, 255) if c < t else (0, 255, 0)
                                cv2.rectangle(debug_img, (x, y), (x+w, y+h), color, 2)
                                cv2.putText(debug_img, f"{c}/{t}", (x, y-5),
                                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
                        except ValueError:
                            pass
        
        if save_debug and debug_img is not None:
            cv2.imwrite('hours_detection_debug.png', debug_img)
        
        return hours_data
    
    def _merge_overlapping_regions(self, regions):
        """åˆå¹¶é‡å çš„åŒºåŸŸ"""
        if not regions:
            return []
        
        # æŒ‰Yåæ ‡æ’åº
        regions.sort(key=lambda r: r['y'])
        
        merged = []
        for region in regions:
            if not merged:
                merged.append(region)
                continue
            
            # æ£€æŸ¥æ˜¯å¦ä¸æœ€åä¸€ä¸ªåŒºåŸŸé‡å 
            last = merged[-1]
            
            # è®¡ç®—é‡å 
            x_overlap = (region['x'] < last['x'] + last['width'] and 
                        region['x'] + region['width'] > last['x'])
            y_overlap = (region['y'] < last['y'] + last['height'] and 
                        region['y'] + region['height'] > last['y'])
            
            if x_overlap and y_overlap:
                # åˆå¹¶
                x1 = min(last['x'], region['x'])
                y1 = min(last['y'], region['y'])
                x2 = max(last['x'] + last['width'], region['x'] + region['width'])
                y2 = max(last['y'] + last['height'], region['y'] + region['height'])
                
                merged[-1] = {
                    'x': x1,
                    'y': y1,
                    'width': x2 - x1,
                    'height': y2 - y1
                }
            else:
                merged.append(region)
        
        return merged
    
    def detect_list_items(self, image):
        """
        æ£€æµ‹åˆ—è¡¨é¡¹
        
        ä¼˜åŒ–ç‚¹ï¼š
        - åŸºäºæ°´å¹³åˆ†éš”çº¿
        - è€ƒè™‘å¹³å‡é—´è·
        - åŒºåˆ†ä¸€çº§å’ŒäºŒçº§åˆ—è¡¨
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        height, width = image.shape[:2]
        
        # æ£€æµ‹æ°´å¹³çº¿
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (width // 2, 1))
        detect_horizontal = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, horizontal_kernel)
        edges = cv2.Canny(detect_horizontal, 50, 150)
        
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100,
                               minLineLength=width//3, maxLineGap=20)
        
        horizontal_lines = []
        if lines is not None:
            for line in lines:
                x1, y1, x2, y2 = line[0]
                if abs(y2 - y1) < 5:  # æ°´å¹³çº¿
                    horizontal_lines.append({
                        'y': (y1 + y2) // 2,
                        'x1': x1,
                        'x2': x2,
                        'length': abs(x2 - x1)
                    })
        
        # å»é‡
        horizontal_lines.sort(key=lambda l: l['y'])
        unique_lines = []
        for line in horizontal_lines:
            if not unique_lines or abs(line['y'] - unique_lines[-1]['y']) > 10:
                unique_lines.append(line)
        
        # æ ¹æ®åˆ†éš”çº¿åˆ’åˆ†åˆ—è¡¨é¡¹
        list_items = []
        for i in range(len(unique_lines) - 1):
            y_start = unique_lines[i]['y']
            y_end = unique_lines[i + 1]['y']
            item_height = y_end - y_start
            
            # è¿‡æ»¤å¤ªå°çš„é¡¹
            if item_height > 30:
                list_items.append({
                    'index': len(list_items) + 1,
                    'y_start': y_start,
                    'y_end': y_end,
                    'height': item_height,
                    'center_y': (y_start + y_end) // 2
                })
        
        return list_items


def demo_recognition():
    """æ¼”ç¤ºä¼˜åŒ–çš„è¯†åˆ«"""
    print("=" * 60)
    print("ä¼˜åŒ–è¯†åˆ«æ¼”ç¤º")
    print("=" * 60)
    
    # åŠ è½½å›¾ç‰‡
    image = cv2.imread('lists_full.png')
    if image is None:
        print("âŒ æ— æ³•åŠ è½½å›¾ç‰‡")
        return
    
    print(f"âœ… å›¾ç‰‡å·²åŠ è½½: {image.shape[1]}x{image.shape[0]}")
    
    # åˆ›å»ºè¯†åˆ«å™¨
    recognizer = OptimizedRecognizer()
    
    # 1. æ£€æµ‹çº¢è‰²æŒ‰é’®
    print("\nğŸ”´ æ£€æµ‹ä¸€çº§èœå•æŒ‰é’®...")
    red_buttons = recognizer.detect_red_buttons(image)
    print(f"   æ‰¾åˆ° {len(red_buttons)} ä¸ªçº¢è‰²æŒ‰é’®")
    for i, btn in enumerate(red_buttons):
        print(f"   æŒ‰é’® {i+1}: ä½ç½®({btn['center_x']}, {btn['center_y']}), é¢ç§¯{btn['area']}pxÂ²")
    
    # 2. æ£€æµ‹åˆ—è¡¨é¡¹
    print("\nğŸ“‹ æ£€æµ‹åˆ—è¡¨ç»“æ„...")
    list_items = recognizer.detect_list_items(image)
    print(f"   æ‰¾åˆ° {len(list_items)} ä¸ªåˆ—è¡¨é¡¹")
    for item in list_items[:5]:
        print(f"   é¡¹ {item['index']}: Y={item['y_start']}~{item['y_end']} (é«˜åº¦{item['height']}px)")
    
    # 3. æ£€æµ‹å­¦æ—¶ä¿¡æ¯
    if HAS_OCR:
        print("\nâ° æ£€æµ‹å­¦æ—¶ä¿¡æ¯...")
        hours_data = recognizer.detect_hours_pattern(image, save_debug=True)
        print(f"   æ‰¾åˆ° {len(hours_data)} ä¸ªå­¦æ—¶ä¿¡æ¯")
        
        incomplete = [h for h in hours_data if h['incomplete']]
        complete = [h for h in hours_data if not h['incomplete']]
        
        print(f"   æœªå®Œæˆ: {len(incomplete)} ä¸ª")
        print(f"   å·²å®Œæˆ: {len(complete)} ä¸ª")
        
        for i, h in enumerate(hours_data[:5]):
            status = "âŒ" if h['incomplete'] else "âœ…"
            print(f"   {i+1}. {h['text']} {status}")
    else:
        print("\nâš ï¸  OCRæœªå®‰è£…ï¼Œè·³è¿‡å­¦æ—¶æ£€æµ‹")
    
    print("\n" + "=" * 60)
    print("âœ… æ¼”ç¤ºå®Œæˆ")
    print("=" * 60)


if __name__ == '__main__':
    demo_recognition()

